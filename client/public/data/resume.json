{
  "cv": {
    "name": "Subhayu Kumar Bala",
    "resume_url": "https://subhayu99.github.io/resume.pdf",
    "location": "Kolkata, India",
    "email": "balasubhayu99@gmail.com",
    "phone": "tel:+91-9382877751",
    "website": "https://subhayu99.github.io/",
    "social_networks": [
      {
        "network": "LinkedIn",
        "username": "subhayu-kumar-bala"
      },
      {
        "network": "GitHub",
        "username": "subhayu99"
      }
    ],
    "sections": {
      "intro": [
        "A Data & Infrastructure Engineer with 3+ years of experience building high-performance, intelligent systems that drive measurable business outcomes. I specialize in turning complex data problems into efficient, scalable software.",
        "I leverage deep expertise in Python, SQL, and multi-cloud architecture (AWS/Azure/GCP) to deliver transformative results, from slashing a 27-hour data process to just 5 seconds to engineering production-grade agentic LLMs.",
        "My work has directly contributed to critical business milestones for clients, including enabling a startup to secure a $6M Series A funding round and ensuring enterprise-grade data compliance for regulated industries."
      ],
      "technologies": [
        {
          "label": "Core Languages & Tools",
          "details": "Python, SQL, BASH, JavaScript, Git"
        },
        {
          "label": "Data Engineering & Orchestration",
          "details": "ETL/ELT Pipelines, Data Modeling, PySpark, Pandas, NumPy, DuckDB, DBT, Airflow, GCP Workflows, Kafka, RabbitMQ, Microsoft Fabric, ADF, Treasure Data, GeoPandas, PostGIS"
        },
        {
          "label": "AI & LLM Engineering",
          "details": "OpenAI APIs, Gemini, LangChain, Agentic Architecture (MCP, A2A), RAG, Axolotl, LLM Fine-tuning (SFT, DPO), Prompt Engineering, Semantic Deduplication, TensorFlow, Keras, SerpAPI"
        },
        {
          "label": "Cloud & DevOps",
          "details": "AWS, Azure, GCP, S3, Docker, Kubernetes, Terraform, Pulumi, ARM Templates, CI/CD Pipelines, Jenkins, Azure DevOps, NGINX, Linux, Cloud Cost Optimization"
        },
        {
          "label": "Application & API Development",
          "details": "FastAPI, Django, DRF, Flask, REST APIs, Typer CLI"
        },
        {
          "label": "Databases & Vector Stores",
          "details": "PostgreSQL, MongoDB, BigQuery, MS SQL Server, MySQL, Neo4j, Chroma, FAISS"
        },
        {
          "label": "Security & Quality Assurance",
          "details": "Zero-Trust Architecture, Cryptography (E2EE, AES-GCM, RSA), IAM, OAuth2/JWT, SSO/SAML, RBAC, Secret Management, Pytest, Unittest, Pydantic, Pandera, Great Expectations"
        },
        {
          "label": "Specialized & Visualization",
          "details": "CDPs, SFMC, Web Scraping, Looker Studio, PowerBI, Streamlit, Plotly, Matplotlib, Quantum Computing Simulation, Agile (Scrum/Kanban), Code Reviews, Technical Consultation & Solution Design"
        }
      ],
      "experience": [
        {
          "company": "FiftyFive Technologies",
          "position": "Data Engineer",
          "location": "Gurugram, India (Remote)",
          "start_date": "2022-06",
          "highlights": [
            "<b>Delivered >99.99% Performance Gains:</b> Re-architected a 27.5-hour legacy SQL procedure into a 5-second Python/DuckDB process, successfully handling 80M+ financial records and unlocking significant operational efficiency for the client.",
            "<b>Engineered and Shipped Production AI:</b> Built and deployed a production-grade agentic LLM system from the ground up, using fine-tuned Mistral/Llama models to achieve >95% accuracy in real-time data processing and tool orchestration.",
            "<b>Enabled a $6M Series A Funding Round:</b> Architected the foundational data platform from scratch on GCP for a high-growth startup, providing the critical infrastructure and real-time analytics that were instrumental in their successful funding.",
            "<b>Ensured Enterprise Data Compliance:</b> Implemented robust data pipelines for a major healthcare client (Johnson & Johnson), engineering complex consent logic to meet strict data governance and privacy standards in regulated markets."
          ]
        },
        {
          "company": "FiftyFive Technologies",
          "position": "SWE Intern",
          "location": "Gurugram, India (Remote)",
          "start_date": "2022-01",
          "end_date": "2022-05",
          "highlights": [
            "Contributed across the full development lifecycle, from building a geospatial backend platform that earned direct client commendation to establishing CI/CD pipelines on Azure DevOps for services supporting 50k+ daily users."
          ]
        }
      ],
      "education": [
        {
          "institution": "CIEM",
          "location": "Kolkata",
          "area": "Information Technology",
          "degree": "B.Tech",
          "start_date": "2018-07",
          "end_date": "2022-06",
          "highlights": [
            "CGPA: <b>8.57</b>/10 ([Certificate](https://drive.google.com/file/d/1xX8XtAlEEnXSgkcJ3jYmYSJOQWRylA6S/view))"
          ]
        }
      ],
      "selected_projects": [
        {
          "name": "Johnson & Johnson - Healthcare Data Platform",
          "date": "Feb 2025 – Jun 2025",
          "highlights": [
            "Architected and maintained scalable data pipelines (Bronze-Silver-Gold layers) in Treasure Data using SQL, processing millions of records for JP and ANZ Healthcare Professionals' marketing analytics.",
            "Engineered complex data transformation logic including a 12-scenario truth table for multichannel consent processing, integrating data across platforms (CDP, S3, Treasure Data, SFMC, GA4) using Python and APIs.",
            "Ensured enterprise-grade data quality and pipeline reliability by implementing robust consistency checks and automated data processing workflows for regulated healthcare environments."
          ]
        },
        {
          "name": "Wade Insight - Cloud-Native Data Orchestration Platform",
          "date": "Nov 2024 – Feb 2025",
          "highlights": [
            "Enhanced core pipeline orchestration features for WADE's Azure SaaS platform, implementing comprehensive continue_on_failure mechanisms with SQL dependency handling and advanced job execution tracking.",
            "Led migration of enterprise data pipelines from Azure Data Factory to Microsoft Fabric Data Factory, managing ARM template adaptation and deployment for clients processing millions of records.",
            "Developed automated healthcheck processes leveraging Azure APIs to monitor running pipelines, reducing manual troubleshooting overhead by 80% and enabling faster insight delivery."
          ]
        },
        {
          "name": "Prospexs - AI-Powered Outreach Platform",
          "date": "Jul 2024 – Oct 2024",
          "highlights": [
            "Built an AI-powered outreach platform using Python/FastAPI and MongoDB, reducing manual prospecting effort by 60% through intelligent automation.",
            "Integrated multiple APIs (OpenAI, Perplexity, LinkedIn) to validate profiles and generate personalized communications, improving client response rates by 45%.",
            "Developed email generation system with dynamic tone adjustment capabilities, enabling scalable personalized outreach for B2B sales teams."
          ]
        },
        {
          "name": "QxLab - State-of-the-Art Agent-Based LLM System",
          "date": "Jan 2024 – Jun 2024",
          "highlights": [
            "Built a production-ready agent-based LLM system using fine-tuned Mistral7B and Llama 13B models for real-time API data processing, achieving over 95% accuracy with custom schema management for tool orchestration.",
            "Developed advanced CLI tool with Typer for language model fine-tuning and dataset manipulation, processing millions of data points and 10B+ tokens in minutes through optimized pipelines.",
            "Orchestrated FastAPI deployment on Docker for GPU-accelerated model inference with multi-threading capabilities, enabling scalable AI model serving infrastructure."
          ]
        },
        {
          "name": "CV Advisors - High-Performance Financial Data Processing",
          "date": "Jan 2024 – Jan 2024",
          "highlights": [
            "Developed a Python/Pandas/DuckDB proof-of-concept for financial data processing pipeline, reducing runtime of a 1900+ line SQL procedure from 27.5 hours to under 5 seconds.",
            "Demonstrated Python's capability for high-performance data processing on 80M+ rows across 150 clients, enabling batch execution and significant operational efficiency improvements."
          ]
        },
        {
          "name": "Logical Contract - AI-Powered Contract Generator",
          "date": "Oct 2023 — Dec 2023",
          "highlights": [
            "Implemented an AI-powered system to generate tailored employment agreements for startups.",
            "Developed a legal chatbot that catered to legal inquiries, offering tailored responses based on user data."
          ]
        },
        {
          "name": "SlideNinja - AI-Powered Presentation Generator",
          "date": "Jul 2023 — Oct 2023",
          "highlights": [
            "Created a RAG-based AI platform (using GPT-3.5, Langchain, ChromaDB, Python, SerpApi) to generate presentations by providing just the title, description, slide count and optionally custom documents.",
            "Developed backend APIs for managing user authentication, presentation generation, and file uploads."
          ]
        },
        {
          "name": "LoopKitchen (now Loop) - Food Delivery Intelligence Platform",
          "date": "Sep 2022 – Jun 2023",
          "highlights": [
            "Built core data infrastructure from scratch for a food delivery analytics startup using comprehensive GCP stack: FastAPI/SQLModel APIs on Cloud Run/Functions, BigQuery for data warehousing, Firestore for metadata, orchestrated via GCP Composer and Workflows.",
            "Developed multi-platform data ingestion pipelines scraping and processing millions of orders from UberEats, DoorDash, and Grubhub APIs, enabling real-time performance analytics for restaurant brands and franchises.",
            "Created custom Streamlit monitoring dashboard providing real-time visibility into complex orchestration workflows with granular tracking (brand→region→chain→store→order level), essential for debugging long-running processes across multiple third-party platforms.",
            "Contributed as core team member (10-person startup) working directly with technical leadership, helping build the foundation for a platform that secured $6M Series A funding and now serves major restaurant chains like Dave's Hot Chicken and Freddy's."
          ]
        },
        {
          "name": "Eningo - Automated Cable & Utility Mapping Platform",
          "date": "Apr 2022 — Aug 2022",
          "highlights": [
            "Developed a cloud-based platform for automating cable network issue requests and processing geospatial data.",
            "Migrated legacy data from Postgres to MongoDB, enhancing scalability and efficiency."
          ]
        },
        {
          "name": "NIBE - DevOps Automation for Sustainable Energy Tech",
          "date": "Feb 2022 — Mar 2022",
          "highlights": [
            "Created and managed CI/CD pipelines on Azure DevOps, impacting over 50k daily users."
          ]
        }
      ],
      "personal_projects": [
        {
          "name": "DatasetPipeline",
          "date": "May 2025",
          "highlights": [
            "Developed a production-ready CLI tool for transforming messy datasets into ML-ready formats; supports SFT, DPO, semantic deduplication, and quality analysis with plugin architecture.",
            "Features smart role mapping, auto-formatting for OpenAI-style training, and reproducible workflows via YAML/JSON configuration for enterprise ML pipelines.",
            "Published on [PyPI](https://pypi.org/project/datasetpipeline) and open-sourced on [GitHub](https://github.com/subhayu99/datasetpipeline) with extensible architecture for custom loaders, formatters, and analyzers."
          ]
        },
        {
          "name": "Smart Commit",
          "date": "May 2025",
          "highlights": [
            "Built an AI-powered CLI tool using Python/Typer that generates context-aware git commits via OpenAI or Anthropic models, enhancing developer productivity and project history quality.",
            "Intelligently adapts to different projects by analyzing the existing tech stack, commit history, and file changes, ensuring contextually relevant and consistent messages.",
            "Published on [PyPI](https://pypi.org/project/smart-commit-ai) and [GitHub](https://github.com/subhayu99/smart-commit) with Model Context Protocol (MCP) server for direct AI assistant integration."
          ]
        },
        {
          "name": "DocumentAccessPOC",
          "date": "Feb 2025",
          "highlights": [
            "Designed and built a zero-trust secure document system to solve granular access control challenges where traditional RBAC/ACLs fail, ensuring data confidentiality even from system administrators.",
            "Implemented a robust cryptographic model featuring end-to-end encryption (AES-GCM) and secure key exchange (RSA) to enforce permissions at a data level, not just application logic.",
            "Built a FastAPI interface for secure document sharing and revocation, with the full project documented and open-sourced on [GitHub](https://github.com/subhayu99/DocumentAccessPOC)."
          ]
        },
        {
          "name": "creatree",
          "date": "Feb 2025",
          "highlights": [
            "Developed a Python CLI tool and library for automating directory structure creation from tree-like strings, solving the repetitive manual setup of project scaffolding and templates.",
            "Designed for maximum flexibility with both a Python library for programmatic integration and a CLI supporting stdin/pipes, including a unique feature to inject setup comments into new files.",
            "Published on [PyPI](https://pypi.org/project/creatree) and open-sourced on [GitHub](https://github.com/subhayu99/creatree) with both programmatic API and CLI interfaces supporting stdin for flexible scripting workflows."
          ]
        },
        {
          "name": "BetterPassphrase",
          "date": "Jan 2024",
          "highlights": [
            "Built a Python CLI tool and library for generating secure, memorable passphrases using grammatically correct phrases with customizable word counts, separators, and capitalization options.",
            "Implemented probabilistic security analysis with entropy calculations and parts-of-speech parsing to balance memorability with cryptographic strength for authentication systems.",
            "Published on [PyPI](https://pypi.org/project/BetterPassphrase) and open-sourced on [GitHub](https://github.com/subhayu99/BetterPassphrase) with comprehensive CLI interface supporting batch generation and file output for enterprise workflows."
          ]
        },
        {
          "name": "FINADICT - Financial Prediction App",
          "date": "Sep 2021",
          "highlights": [
            "Built an interactive financial forecasting tool with Streamlit, enabling users to analyze and predict market data for stocks, forex, and cryptocurrencies.",
            "Implemented a suite of analytical features, including price forecasting via FB Prophet, interactive Plotly visualizations, and downloadable data reports.",
            "Managed the project's full lifecycle from development to deployment, containerizing the app with Docker and maintaining it as a live, public-facing service. Now open-sourced on [GitHub](https://github.com/subhayu99/finadict)."
          ]
        }
      ],
      "publication": [
        {
          "title": "QuDiet: A Classical Simulation Platform for Qubit-Qudit Hybrid Quantum Systems",
          "authors": [
            "Subhayu Kumar Bala",
            "Turbasu Chatterjee",
            "Arnav Das"
          ],
          "date": "2023-03-28",
          "journal": "IET Quantum Communication",
          "doi": "10.1049/qtc2.12058"
        }
      ]
    }
  }
}